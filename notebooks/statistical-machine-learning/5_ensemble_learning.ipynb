{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fab18e9d-83fb-44e0-9020-9f3bab78cedb",
   "metadata": {},
   "source": [
    "### <div align=\"center\">Ensemble Learning - Classification</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86ee06c-4611-4460-9765-575c39d3d1eb",
   "metadata": {},
   "source": [
    "##### 5.1: What is Ensemble Learning ?\n",
    "- Ensemble learning is a strategy in machine learning where we join predictions from several models. This approach helps us get a more precise and resilient forecast. \n",
    "- It can be achieved using any of the techniques below\n",
    "  - Basic Techniques:\n",
    "    1. Majority Vote\n",
    "    2. Average\n",
    "    3. Weighted Average\n",
    "  - Advanced Techniques:\n",
    "    1. Bagging\n",
    "    2. Boosting\n",
    "    3. Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec87bab-0ebe-436f-b826-120deca0de25",
   "metadata": {},
   "source": [
    "##### 5.2: Majority Voting, Average and Weighted Average\n",
    "- The voting classifier (sklearn.ensemble.VotingClassifier) typically employs the \"hard\" method, which is based on majority rule voting. However, for classifiers that are well-calibrated, the \"soft\" method is suggested. This method determines class labels according to the argmax of the predicted probabilities.\n",
    "- In weighted average, we can provide the more weight to trusted model and calculate the vote.\n",
    "- The Voting Regressor method will be used for regression, just as the Voting Classifier demonstrated for classification in the video."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6363db38-4bb2-4f4d-bed5-de18217434cd",
   "metadata": {},
   "source": [
    "##### 5.3: Bagging\n",
    "- Bagging in ensemble learning is a technique where paralelly multiple models are trained on random subsets of the training data and their predictions are aggregated to improve accuracy and reduce variance.\n",
    "- Random sampling with replacement is also called bootstrapping.\n",
    "- Each model in ensemble learning is called a Base learner.\n",
    "- Bagging is also known as bootstrap aggregating.\n",
    "- Benefit of bagging\n",
    "  - Robust against Outliers (Since it is an aggregated sum of base learner).\n",
    "  - Reduction in Variance (May be one or two model will be overfit but still due to aggregated value variance will be less).\n",
    "  - A good way to handle high dimensional (More feature).\n",
    "  - Improved Accuracy (Due to wisdom of croud)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725575a1-8641-4f6a-a6f0-8318f629bbb7",
   "metadata": {},
   "source": [
    "##### 5.4: Bagging - Random Forest\n",
    "- Random forest stands as one of the two key algorithms in Machine Learning.\n",
    "- A random forest is a learning method that constructs multiple decision trees on random data subsets and features during the training phase, delivering the class that represents the mode of the classes or the average prediction of the individual trees.\n",
    "- In random forest we do row and column sampling (For each model we can choose random column/feature).\n",
    "- The use of random forest provides a unique perspective on the data, enhancing the robustness of your model.\n",
    "##### 5.5: Random Forest - Raisin Classification\n",
    "- Random Forest is versatile, suitable for both classification and regression tasks.\n",
    "- All models in the Random Forest share the same decision tree criterion.\n",
    "- Depending on the specific use case or scenario, parameters and arguments can be adjusted for optimal model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafa96b1-7fe5-431c-8cbb-afccfbb00d98",
   "metadata": {},
   "source": [
    "##### 5.8: Boosting - AdaBoost\n",
    "- Boosting in machine learning is a sequential process where multiple models, typically weak learners, are trained one after the other, with each model building upon the errors of its predecessor to improve overall accuracy and form a strong predictive model.\n",
    "- Different Boosting Techniques:\n",
    "  - AdaBoost\n",
    "  - Gradient Boost\n",
    "  - XGBoost (eXtreme Gradient Boosting)\n",
    "  - LightGBM\n",
    "  - CatBoost\n",
    "- A Decision Stump is a tree that has one root node and two child nodes.\n",
    "- AdaBoost is a machine learning algorithm that adjusts training instances’ weights based on prior models’ errors. It emphasizes wrongly predicted instances, increases their weights, and enhances the ensemble’s overall accuracy.\n",
    "- class sklearn.ensemble.AdaBoostClassifier(estimator=None, n_estimators=50, learning_rate=1.0, algorithm='SAMME.R', random_state=None)\n",
    "- Formulas Used:\n",
    "  - Total Error – It is a sum of the weight of all the incorrect predictions\n",
    "  - Amount of Say (α) = (½) log ( (1 - error) / error )\n",
    "  - Correct Prediction → New weight = old weight × e^(–α)\n",
    "  - Incorrect Prediction → New weight = old weight × e^(α)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73972703-9124-44af-936c-1e8b3a873ac4",
   "metadata": {},
   "source": [
    "##### 5.9: Gradient Boosting: Regression Walk Through\n",
    "- Gradient boosting is an ensemble machine learning technique that iteratively trains decision trees on residual errors, combining them with a learning rate to improve model accuracy progressively.\n",
    "- Gradient Boost is the sequence of weak learner and the first week learner is the mean called prediction.\n",
    "- Residual = Actual - Predicted (mean) \n",
    "- The residuals can be referred to as pseudo-residuals.\n",
    "- Fₖ(x) = F₀(x) + Learning Rate * PR1 + Learning Rate * PR2 + ….. + Learning Rate * PRK\n",
    "- n_estimators is equal to no of weak learners in parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773ed042-9bf7-4211-a646-fc8eca01a889",
   "metadata": {},
   "source": [
    "##### 5.14: Gradient Boosting: Classification\n",
    "- In Regression we use loss function as Mean Squared Error and in Classification we use Logistic loss (Log loss).\n",
    "- Gradient Boosting applies a similar method for both classification and regression, with the only difference being the loss function – Logistic Loss for classification and Mean Squared Error for regression.\n",
    "- When contrasted with a decision tree or random forest, gradient boosting has a slight edge in terms of performance and overall prediction accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d73cab-12ba-4656-a3ad-910bf74b1365",
   "metadata": {},
   "source": [
    "<h3 align=\"center\">Gradient Boosting Classifier: Titanic Survival</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d6fe09a-f3b3-4ee9-8bec-a22ea9bebe7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Siblings/Spouses Aboard</th>\n",
       "      <th>Parents/Children Aboard</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr. Owen Harris Braund</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs. John Bradley (Florence Briggs Thayer) Cum...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Miss. Laina Heikkinen</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs. Jacques Heath (Lily May Peel) Futrelle</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr. William Henry Allen</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass                                               Name  \\\n",
       "0         0       3                             Mr. Owen Harris Braund   \n",
       "1         1       1  Mrs. John Bradley (Florence Briggs Thayer) Cum...   \n",
       "2         1       3                              Miss. Laina Heikkinen   \n",
       "3         1       1        Mrs. Jacques Heath (Lily May Peel) Futrelle   \n",
       "4         0       3                            Mr. William Henry Allen   \n",
       "\n",
       "      Sex   Age  Siblings/Spouses Aboard  Parents/Children Aboard     Fare  \n",
       "0    male  22.0                        1                        0   7.2500  \n",
       "1  female  38.0                        1                        0  71.2833  \n",
       "2  female  26.0                        0                        0   7.9250  \n",
       "3  female  35.0                        1                        0  53.1000  \n",
       "4    male  35.0                        0                        0   8.0500  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Data\n",
    "#Dataset Citation: This dataset was downloaded from standford university website. \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# df = pd.read_csv(\"https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv\")\n",
    "df = pd.read_csv(\"../data/titanic.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28e61148-2c65-4abe-a7a6-10fe513fb364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(887, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86a303ef-42fb-41fb-bd25-1ea06e03e067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived                   0\n",
       "Pclass                     0\n",
       "Name                       0\n",
       "Sex                        0\n",
       "Age                        0\n",
       "Siblings/Spouses Aboard    0\n",
       "Parents/Children Aboard    0\n",
       "Fare                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "431d793b-816f-477d-8791-4d5acda05848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Siblings/Spouses Aboard</th>\n",
       "      <th>Parents/Children Aboard</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr. Owen Harris Braund</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs. John Bradley (Florence Briggs Thayer) Cum...</td>\n",
       "      <td>2</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Miss. Laina Heikkinen</td>\n",
       "      <td>2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass                                               Name  Sex  \\\n",
       "0         0       3                             Mr. Owen Harris Braund    1   \n",
       "1         1       1  Mrs. John Bradley (Florence Briggs Thayer) Cum...    2   \n",
       "2         1       3                              Miss. Laina Heikkinen    2   \n",
       "\n",
       "    Age  Siblings/Spouses Aboard  Parents/Children Aboard     Fare  \n",
       "0  22.0                        1                        0   7.2500  \n",
       "1  38.0                        1                        0  71.2833  \n",
       "2  26.0                        0                        0   7.9250  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sex'] = df['Sex'].map({'male': 1,  'female': 2})\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8234c79-1be8-4376-ac78-256ee40106c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Siblings/Spouses Aboard</th>\n",
       "      <th>Parents/Children Aboard</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex   Age  Siblings/Spouses Aboard  \\\n",
       "0         0       3    1  22.0                        1   \n",
       "1         1       1    2  38.0                        1   \n",
       "2         1       3    2  26.0                        0   \n",
       "\n",
       "   Parents/Children Aboard     Fare  \n",
       "0                        0   7.2500  \n",
       "1                        0  71.2833  \n",
       "2                        0   7.9250  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop Name column which is not useful in determining the survival rate\n",
    "df.drop(\"Name\", axis=\"columns\", inplace=True)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "989e4592-418f-481e-842e-0d58ea58f6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "X = df.drop('Survived',axis=\"columns\")\n",
    "y = df['Survived']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acce1948-7f3c-4fd3-928d-da5a9088fab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82       166\n",
      "           1       0.71      0.71      0.71       101\n",
      "\n",
      "    accuracy                           0.78       267\n",
      "   macro avg       0.77      0.77      0.77       267\n",
      "weighted avg       0.78      0.78      0.78       267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model Training Using Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2aaa8a1-20a0-40fe-a70c-b7f4487a7b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.91      0.86       166\n",
      "           1       0.82      0.67      0.74       101\n",
      "\n",
      "    accuracy                           0.82       267\n",
      "   macro avg       0.82      0.79      0.80       267\n",
      "weighted avg       0.82      0.82      0.82       267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model Training Using Gradient Boost\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "model = GradientBoostingClassifier(n_estimators=100)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3640ecd9-bfbf-4477-89fe-9247bc95f1a7",
   "metadata": {},
   "source": [
    "If you compare classification report across decision tree, random forest and gradient boost, you will notice slight improvement in precision, recall and accuracy when we use gradient boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db55e3f-5f5d-4109-8193-3c66c1f7e460",
   "metadata": {},
   "source": [
    "##### 5.15: XGBoost - Walk Through\n",
    "- XGBoost is the Powerful and widely used statistical machine learning algorithm in industry.\n",
    "- XGBoost is a high-performance machine learning library that constructs decision trees using exact and approximate algorithms for split finding. It uses post-growth tree pruning to enhance model accuracy and scalability, particularly for large datasets, while minimizing over fitting.\n",
    "- Logistic regression is good when we have linear relationship between features and target variable where as XGBoost is tree based learning model and is good at capturing non linear relationship. It uses weak classifier (Wisdom of croud)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1682383-f685-462e-b201-d3dd6762bc66",
   "metadata": {},
   "source": [
    "##### 5.18: XGBoost - Benefits\n",
    "- High Accuracy\n",
    "  1. Better at modeling complex non-linear relationships due to tree-based learning and boosting approach.\n",
    "  2. In built regularization\n",
    "  3. Automatic Handling of missing values\n",
    "  4. Feature importance and selection\n",
    "- Very Fast\n",
    "  1. Tree Pruning\n",
    "  2. Block structure and parallel processing\n",
    "  3. Cache Awareness\n",
    "  4. Efficient Handling of Sparse Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd85c0a-3a4c-487f-a57c-39e8e5bf4a6d",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "\n",
    "You are a data scientist / AI engineer working on a classification problem to predict the quality of milk. You have been provided with a dataset named **`\"milk_quality_data.csv\"`**, which includes various parameters that affect milk quality. The dataset comprises the following columns:\n",
    "\n",
    "- `ph:` The pH level of the milk.\n",
    "- `temperature:` The temperature of the milk.\n",
    "- `taste:` Whether the taste is good or bad (1 for good, 0 for bad).\n",
    "- `odor:` Whether the odor is good or bad (1 for good, 0 for bad).\n",
    "- `fat:` Whether the fat content is optimal or not (1 for optimal, 0 for not).\n",
    "- `turbidity:` Whether the turbidity is high or low (1 for high, 0 for low).\n",
    "- `colour:` The color value of the milk.\n",
    "- `grade:` The quality of the milk (low, medium, high).\n",
    "  \n",
    "Your task is to use this dataset to build and evaluate machine learning models to predict the grade of the milk based on the given parameters. You will perform data preprocessing, exploratory data analysis, and model training using different algorithms, including logistic regression, decision tree, gradient boosting, and XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bc448b5-7466-403c-9f1c-9f1a2ac82bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Necessary Libraries\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a9f68c-92bd-45f7-9b29-5e63308b391c",
   "metadata": {},
   "source": [
    "### Task 1: Data Preparation and Exploration\n",
    "\n",
    "1. Import the data from the `\"milk_quality_data.csv\"` file and store it in a variable df.\n",
    "2. Display the number of rows and columns in the dataset.\n",
    "3. Display the first few rows of the dataset to get an overview.\n",
    "4. Check for any missing values in the dataset and handle them appropriately.\n",
    "5. Encode the target variable `grade` by mapping it to numbers `(low = 0, medium = 1, high = 2)`.\n",
    "6. Visualize the distribution of key features `(ph, temperature)` using histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0dd15aaf-7873-45ab-b2ba-9fbbcb362b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows and columns: (1059, 8)\n",
      "First few rows of the dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ph</th>\n",
       "      <th>temperature</th>\n",
       "      <th>taste</th>\n",
       "      <th>odor</th>\n",
       "      <th>fat</th>\n",
       "      <th>turbidity</th>\n",
       "      <th>colour</th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.6</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>254</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.6</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>253</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>246</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.5</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>255</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.6</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ph  temperature  taste  odor  fat  turbidity  colour   grade\n",
       "0  6.6           35      1     0    1          0     254    high\n",
       "1  6.6           36      0     1    0          1     253    high\n",
       "2  8.5           70      1     1    1          1     246     low\n",
       "3  9.5           34      1     1    0          1     255     low\n",
       "4  6.6           37      0     0    0          0     255  medium"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Import the data from the \"milk_quality_data.csv\" file and store it in a variable 'df'\n",
    "df = pd.read_csv(\"../data/milk_quality_data.csv\")\n",
    "\n",
    "# Step 2: Display the number of rows and columns in the dataset\n",
    "print(\"Number of rows and columns:\", df.shape)\n",
    "\n",
    "# Step 3: Display the first few rows of the dataset to get an overview\n",
    "print(\"First few rows of the dataset:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f87dd06-5c32-4b21-8c3d-1b32e498ca63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in the dataset:\n",
      "ph             0\n",
      "temperature    0\n",
      "taste          0\n",
      "odor           0\n",
      "fat            0\n",
      "turbidity      0\n",
      "colour         0\n",
      "grade          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Check for any missing values in the dataset and handle them appropriately\n",
    "print(\"Missing values in the dataset:\")\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9fb1dbe-9377-46cc-ba63-260303926834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Encode the target variable 'grade' by mapping it to numbers ('low' = 0, 'medium' = 1, 'high' = 2)\n",
    "grade_mapping = {'low': 0, 'medium': 1, 'high': 2}\n",
    "df['grade'] = df['grade'].map(grade_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1db55587-41fe-4204-b8c8-fc3ec5db8606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 6: Visualize the distribution of key features ('ph', 'temperature') using histograms\n",
    "df[['ph', 'temperature']].hist(bins=20, figsize=(10, 6))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08302fd7-4216-4cb4-a49c-9d4fe32b4233",
   "metadata": {},
   "source": [
    "### Task 2: Model Training Using Basic Models\n",
    "\n",
    "1. Select the features `(ph, temperature, taste, odor, fat, turbidity, colour)` and the target variable `(grade)` for modeling.\n",
    "2. Split the data into training and test sets with a test size of 30%.\n",
    "3. Initialize and train a Logistic Regression model using the training data.\n",
    "4. Print the model's accuracy score on test data.\n",
    "5. Initialize and train a Decision Tree Classifier using the training data.\n",
    "6. Print the model's accuracy score on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0510e75-f540-400e-bfae-ea6c0272e9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Select the features and target variable for modeling\n",
    "X = df[['ph', 'temperature', 'taste', 'odor', 'fat', 'turbidity', 'colour']]\n",
    "y = df['grade']\n",
    "\n",
    "# Step 2: Split the data into training and test sets with a test size of 30%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf2b5676-3f20-403c-aca8-7c8fe9c6d706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.6981132075471698\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Initialize and train a Logistic Regression model using the training data\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Print the model's accuracy score on test data.\n",
    "logistic_pred = logistic_model.predict(X_test)\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, logistic_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95237b31-8066-485c-b3e6-b3c3cee22657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier Accuracy: 0.9937106918238994\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Initialize and train a Decision Tree Classifier using the training data\n",
    "tree_model = DecisionTreeClassifier()\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 6: Print the model's accuracy score on test data.\n",
    "tree_pred = tree_model.predict(X_test)\n",
    "print(\"Decision Tree Classifier Accuracy:\", accuracy_score(y_test, tree_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946cdb9b-2b5b-4bb2-b808-6d6d6ddede7d",
   "metadata": {},
   "source": [
    "### Task 3: Model Training Using Advanced Models\n",
    "\n",
    "1. Initialize and train a Gradient Boosting Classifier with 50 estimators using the training data.\n",
    "2. Print the model's accuracy score on test data.\n",
    "3. Initialize and train an XGBoost Classifier with 50 estimators using the training data.\n",
    "4. Print the model's accuracy score on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f4db78c-98d8-4f0b-8017-cc8a36f7839c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier Accuracy: 0.9905660377358491\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Initialize and train a Gradient Boosting Classifier with 50 estimators using the training data\n",
    "gb_model = GradientBoostingClassifier(n_estimators=50)\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 2: Print the model's accuracy score\n",
    "gb_pred = gb_model.predict(X_test)\n",
    "print(\"Gradient Boosting Classifier Accuracy:\", accuracy_score(y_test, gb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4545a907-e316-42c5-b961-b3cf8dffb8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classifier Accuracy: 0.9968553459119497\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Initialize and train an XGBoost Classifier with 50 estimators using the training data\n",
    "xgb_model = XGBClassifier(n_estimators=50, use_label_encoder=False, eval_metric='mlogloss')\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Print the model's accuracy score\n",
    "xgb_pred = xgb_model.predict(X_test)\n",
    "print(\"XGBoost Classifier Accuracy:\", accuracy_score(y_test, xgb_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a4c0b7-d2d3-4ac0-bbf8-9b268923bf61",
   "metadata": {},
   "source": [
    "### Task 4: Experiment with Hyperparameters in XGBoost\n",
    "\n",
    "1. Train the XGBoost model with the following parameters\n",
    "    - n_estimators=100\n",
    "    - max_depth=5\n",
    "    - learning_rate=0.1\n",
    "    - colsample_bytree=0.5.\n",
    "\n",
    "Learn about these parameters here: [XgboostClassifier Parameters](https://xgboost.readthedocs.io/en/stable/parameter.html)\n",
    "\n",
    "2. Evaluate the model's performance using accuracy score and print it.\n",
    "3. Print the classification report and confusion matrix for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d8ba474-0773-46e6-a7bf-616eade504e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classifier (Hyperparameters) Accuracy: 0.9968553459119497\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Train the XGBoost model with n_estimators=100, max_depth=5, learning_rate=0.1, colsample_bytree=0.5\n",
    "xgb_model_hyper = XGBClassifier(n_estimators=100, max_depth=5, learning_rate=0.1, colsample_bytree=0.5)\n",
    "xgb_model_hyper.fit(X_train, y_train)\n",
    "\n",
    "# Step 2: Evaluate the model's performance using accuracy score and print it\n",
    "xgb_hyper_pred = xgb_model_hyper.predict(X_test)\n",
    "print(\"XGBoost Classifier (Hyperparameters) Accuracy:\", accuracy_score(y_test, xgb_hyper_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f6fb643-463f-48b4-8e72-f35757c33629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       115\n",
      "           1       0.99      1.00      1.00       127\n",
      "           2       1.00      1.00      1.00        76\n",
      "\n",
      "    accuracy                           1.00       318\n",
      "   macro avg       1.00      1.00      1.00       318\n",
      "weighted avg       1.00      1.00      1.00       318\n",
      "\n",
      "**************************************************\n",
      "Confusion Matrix:\n",
      "[[114   1   0]\n",
      " [  0 127   0]\n",
      " [  0   0  76]]\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Print the classification report and confusion matrix for the model\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, xgb_hyper_pred))\n",
    "\n",
    "print('*' * 50)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, xgb_hyper_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a230624c-a208-41dc-bfe0-a7c48b772d96",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "From the results, we can draw the following conclusions based on the performance metrics achieved by each model:\n",
    "\n",
    "1. **Logistic Regression Model**:\n",
    "    - Accuracy: 0.698\n",
    "    - Provides a baseline performance but struggles to capture complex relationships.\n",
    "<br> </br>\n",
    "2. **Decision Tree Classifier**:\n",
    "    - Accuracy: 0.994\n",
    "    - Shows significant improvement, indicating its ability to manage non-linear relationships and feature interactions.\n",
    "<br> </br>\n",
    "3. **Gradient Boosting Classifier**:\n",
    "    - Accuracy: 0.991\n",
    "    - Slightly improves over the Decision Tree, enhancing robustness by combining multiple weak learners.\n",
    "<br> </br>\n",
    "4. **XGBoost Classifier**:\n",
    "    - Accuracy: 0.997\n",
    "    - Achieves the highest accuracy, demonstrating its effectiveness in preventing overfitting and improving generalization.\n",
    "<br> </br>\n",
    "\n",
    "In conclusion, while Logistic Regression serves as a simple baseline, Decision Tree shows strong performance, and ensemble methods, particularly XGBoost, provide superior performance, making it the best choice for the milk quality prediction task."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
