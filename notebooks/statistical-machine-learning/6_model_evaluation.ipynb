{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "754a95dd-1e42-4642-b39a-b5681620cc87",
   "metadata": {},
   "source": [
    "### <div align=\"center\">Model Evaluation & Fine Tuning</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfc3c6d-2951-4107-80b5-14bd60929d9c",
   "metadata": {},
   "source": [
    "##### 6.2: Model Evaluation - ROC (Receiver Operating Characteristic) Curve & AUC (Area Under Curve)\n",
    "- ROC curve: A graph showing the performance of a classification model by plotting the true positive rate against the false positive rate at various threshold settings.\n",
    "- AUC: A metric that measures the entire two-dimensional area underneath the ROC curve, representing the model’s ability to distinguish between classes.\n",
    "When dealing with stakeholders with model metrics (ROC, AUC, precision, etc.), they won’t understand. The more AUC the better is model performance.\n",
    "- As a data scientist, it is an important skill to translate these metrics into business metrics and discuss in those terms to really make them understand what is the impact."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e61f210-d64d-4d06-9738-3b0d2c86bfb7",
   "metadata": {},
   "source": [
    "##### 6.6: K Fold Cross Validation\n",
    "- K-fold cross-validation is a method where the dataset is split into k subsets (or folds). The model is trained on k-1 folds and tested on the remaining fold. This process is repeated k times, ensuring each fold is used once as the test set, giving a reliable estimate of model performance.\n",
    "- Cross-validation can also be used with the same model but with different parameters.\n",
    "##### 6.7: Stratified K Fold Cross Validation\n",
    "- Stratified K-Fold Cross Validation is a technique that divides data into K subsets while preserving the percentage of samples for each class, ensuring each fold is representative of the entire dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab36c3a-4255-4df8-9605-580c9b3f1060",
   "metadata": {},
   "source": [
    "##### 6.8: Hyperparameter Tuning: GridSearchCV\n",
    "- Hyperparameter Tuning with GridSearchCV involves thoroughly searching a specified parameter grid to identify the best hyperparameter combination for a machine learning model. This is done by evaluating performance through cross-validation.\n",
    "- We should express our gratitude to the open-source contributors who have enhanced scikit-learn, making the work of ML and Data scientists more efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616f44cd-682a-4af7-a776-7490849c7f87",
   "metadata": {},
   "source": [
    "##### 6.9: Hyperparameter Tuning: RandomizedSearchCV\n",
    "- The issue with GridSearchCV is that we need to try out all the combination which is quite expensive.\n",
    "- RandomizedSearchCV is useful when we have huge data and no of parameter want to try is huge.\n",
    "- RandomizedSearchCV is a technique that searches over random combinations of hyperparameters to find the best model configuration using cross-validation, making it more efficient than exhaustive methods.\n",
    "- To optimize computation, we primarily use RandomizedSearchCV. By adjusting just the n_iter parameter, it functions identically to GridSearchCV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036d389f-e9d4-42d7-9eef-3ccde03c4a87",
   "metadata": {},
   "source": [
    "##### 6.12: Model Selection Guide\n",
    "- Machine learning is both a science and an art. As an ML practitioner, you need to use your judgment to choose the right model for each situation.\n",
    "- Since there is no perfect decision tree for model selection, the process can be broadly divided into problem type, column relationships, data type, and data size. Refer to the attached PDF for a detailed guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd0b27c6-b22a-47a3-89ea-d614e833efd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"400\"\n",
       "            src=\"../documents/model_selection_guide.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x29cd67c7b30>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "IFrame(src='../documents/model_selection_guide.pdf', width=1000, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbabe90-42da-46a9-8200-d4a49a8bb138",
   "metadata": {},
   "source": [
    "6.13: Selecting the Right Evaluation Metric\n",
    "- When we print the report we see 2 more parameter (apart from precision, recall etc.) macro avg (Useful in case of balance classes) and weighted avg (Useful in case of class imbalance).\n",
    "- Classifications:\n",
    "  1. Accuracy: Assesses the overall correctness of the model. Particularly useful when classes are balanced.\n",
    "  2. Precision: Indicates the reliability of positive predictions, especially important when false positives are costly.\n",
    "  3. Recall: Focuses on capturing as many positives as possible, crucial when missing a positive is costly.\n",
    "  4. AUC-ROC: Measures how well the model ranks positive instances higher than negative ones.\n",
    "  5. F1 Score: Balances precision and recall, providing a comprehensive performance metric.\n",
    "  6. Confusion Matrix: Offers insights into where the model is making errors, aiding in the assessment of accuracy, precision, recall, and other performance metrics.\n",
    "- Regressions:\n",
    "  1. MSE (Mean Squared Error): Highlights significant errors and is sensitive to outliers.\n",
    "  2. RMSE (Root Mean Square Error): Offers easier interpretation.\n",
    "  3. R² value: Indicates goodness of fit and measures the proportion of variance in the dependent variable predictable from the independent variables."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
