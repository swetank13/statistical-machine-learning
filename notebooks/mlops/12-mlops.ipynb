{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65b481ac-3f67-4392-a943-4b19864946ea",
   "metadata": {},
   "source": [
    "### <div align=\"center\">ML Ops & Cloud Tools</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e38375d-ff99-4981-967a-1590b042add1",
   "metadata": {},
   "source": [
    "#### 12.1: ML Ops\n",
    "- ML Ops is a set of practices to streamline and automate end-to-end machine learning lifecycle.\n",
    "- ML Lifecycle: Develop -> Deploy -> Monitor\n",
    "- ML Ops is similar to Dev Ops in traditional software development.\n",
    "- Model performance can be affected due to:\n",
    "  - Data drift\n",
    "  - Concept drift\n",
    "- Setting up ML Ops in a project offers 3 main benefits:\n",
    "  - Improved efficiency and productivity\n",
    "  - Enhanced quality and reliability\n",
    "  - Better collaboration and governance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87562884-ea16-4c88-b450-003ce4b2008a",
   "metadata": {},
   "source": [
    "#### 12.3: ML Flow: Purpose and Overview\n",
    "- MLflow is an open-source platform that simplifies managing the machine learning lifecycle. It supports MLOps by providing tools for Experiment tracking, Reproducible runs, Model packaging, Model registry.\n",
    "- Benefits of MLflow:\n",
    "  - Experiment Tracking\n",
    "  - Reproducibility & Deployment\n",
    "  - Model Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fef928c-5363-4696-8d82-fbc2895b70d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To install ml flow locally.\n",
    "# pip install mlflow\n",
    "\n",
    "# Run ml flow ui locally\n",
    "# mlflow ui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5fc8ab-2733-493d-acf4-1c43008cd290",
   "metadata": {},
   "source": [
    "#### 12.4: ML Flow Experiment Tracking\n",
    "- MLflow provides an interface and tooling to help ML practitioners with experiment tracking.\n",
    "Experiment tracking is a way by which data scientists and AI engineers can compare different experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2d7776c9-9c37-4ba2-b808-69eea6e053dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c58b6dcb-692c-4311-af4a-64e1625b9399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([900, 100], dtype=int64))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Create an imbalanced binary classification dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=2, n_redundant=8, \n",
    "                           weights=[0.9, 0.1], flip_y=0, random_state=42)\n",
    "\n",
    "np.unique(y, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "16dc3d62-782d-4657-9c05-94ba8c7f826d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f3824c16-c551-418d-8c60-949b24b5508e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95       270\n",
      "           1       0.60      0.50      0.55        30\n",
      "\n",
      "    accuracy                           0.92       300\n",
      "   macro avg       0.77      0.73      0.75       300\n",
      "weighted avg       0.91      0.92      0.91       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Experiment 1: Train Logistic Regression Classifier\n",
    "log_reg = LogisticRegression(C=1, solver='liblinear')\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_log_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "48ba119c-7a27-4dea-9303-9854c32e289e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       270\n",
      "           1       0.95      0.70      0.81        30\n",
      "\n",
      "    accuracy                           0.97       300\n",
      "   macro avg       0.96      0.85      0.89       300\n",
      "weighted avg       0.97      0.97      0.96       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Experiment 2: Train Random Forest Classifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=30, max_depth=3)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3c56e9db-5a45-44a0-a405-7bc59df3d61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       270\n",
      "           1       0.96      0.80      0.87        30\n",
      "\n",
      "    accuracy                           0.98       300\n",
      "   macro avg       0.97      0.90      0.93       300\n",
      "weighted avg       0.98      0.98      0.98       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Experiment 3: Train XGBoost\n",
    "xgb_clf = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f13a32b8-c133-4c49-95fa-952e310e50a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([619, 619], dtype=int64))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experiment 4: Handle class imbalance using SMOTETomek and then Train XGBoost\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "smt = SMOTETomek(random_state=42)\n",
    "X_train_res, y_train_res = smt.fit_resample(X_train, y_train)\n",
    "np.unique(y_train_res, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "06dc3c95-81a2-4e1f-89ec-3c877e96cb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       270\n",
      "           1       0.81      0.83      0.82        30\n",
      "\n",
      "    accuracy                           0.96       300\n",
      "   macro avg       0.89      0.91      0.90       300\n",
      "weighted avg       0.96      0.96      0.96       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_clf = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_clf.fit(X_train_res, y_train_res)\n",
    "y_pred_xgb = xgb_clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1920d5e-4f06-49b2-9d33-dbe2cca5f81b",
   "metadata": {},
   "source": [
    "##### Track Experiments Using MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "66ea2e7b-e7b3-4737-8fdc-c22bb1d7f8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    (\n",
    "        \"Logistic Regression\", \n",
    "        {\"C\": 1, \"solver\": 'liblinear'},\n",
    "        LogisticRegression(), \n",
    "        (X_train, y_train),\n",
    "        (X_test, y_test)\n",
    "    ),\n",
    "    (\n",
    "        \"Random Forest\", \n",
    "        {\"n_estimators\": 30, \"max_depth\": 3},\n",
    "        RandomForestClassifier(), \n",
    "        (X_train, y_train),\n",
    "        (X_test, y_test)\n",
    "    ),\n",
    "    (\n",
    "        \"XGBClassifier\",\n",
    "        {\"use_label_encoder\": False, \"eval_metric\": 'logloss'},\n",
    "        XGBClassifier(), \n",
    "        (X_train, y_train),\n",
    "        (X_test, y_test)\n",
    "    ),\n",
    "    (\n",
    "        \"XGBClassifier With SMOTE\",\n",
    "        {\"use_label_encoder\": False, \"eval_metric\": 'logloss'},\n",
    "        XGBClassifier(), \n",
    "        (X_train_res, y_train_res),\n",
    "        (X_test, y_test)\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f1c11185-c88e-44d7-8022-746849e55f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reports = []\n",
    "\n",
    "for model_name, params, model, train_set, test_set in models:\n",
    "    X_train = train_set[0]\n",
    "    y_train = train_set[1]\n",
    "    X_test = test_set[0]\n",
    "    y_test = test_set[1]\n",
    "    \n",
    "    model.set_params(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    reports.append(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a0371805-09de-487f-b2a7-6779a3473e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c51dd90c-4b79-4dc5-929f-c0fa4cd69c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/15 10:33:46 INFO mlflow.tracking.fluent: Experiment with name 'Anomaly Detection Swetank' does not exist. Creating a new experiment.\n",
      "2025/09/15 10:33:46 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/09/15 10:33:49 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/09/15 10:33:49 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run Logistic Regression at: http://localhost:5000/#/experiments/620974005201839646/runs/18ab1e95bc594775a2c3d1ea41779e2b\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/620974005201839646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/15 10:33:52 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/09/15 10:33:52 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run Random Forest at: http://localhost:5000/#/experiments/620974005201839646/runs/28f8ff51f32749e7bb725d3c7363ccb9\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/620974005201839646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/15 10:33:56 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/09/15 10:33:56 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run XGBClassifier at: http://localhost:5000/#/experiments/620974005201839646/runs/bf95a09ef46a485aad3fabc2589ffd28\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/620974005201839646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/15 10:34:00 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run XGBClassifier With SMOTE at: http://localhost:5000/#/experiments/620974005201839646/runs/3c1fbb5cad934e19997680eef8b2a1f6\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/620974005201839646\n"
     ]
    }
   ],
   "source": [
    "# Initialize MLflow\n",
    "mlflow.set_experiment(\"Anomaly Detection Swetank\")\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "\n",
    "for i, element in enumerate(models):\n",
    "    model_name = element[0]\n",
    "    params = element[1]\n",
    "    model = element[2]\n",
    "    report = reports[i]\n",
    "    \n",
    "    with mlflow.start_run(run_name=model_name):        \n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metrics({\n",
    "            'accuracy': report['accuracy'],\n",
    "            'recall_class_1': report['1']['recall'],\n",
    "            'recall_class_0': report['0']['recall'],\n",
    "            'f1_score_macro': report['macro avg']['f1-score']\n",
    "        })  \n",
    "        \n",
    "        if \"XGB\" in model_name:\n",
    "            mlflow.xgboost.log_model(model, \"model\")\n",
    "        else:\n",
    "            mlflow.sklearn.log_model(model, \"model\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1bf63e-d59d-4adb-850f-66976b28852e",
   "metadata": {},
   "source": [
    "##### Register the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f270b67-1313-44f7-a2a8-c5c7ec2ced85",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'XGB-Smote'\n",
    "run_id=input('Please type RunID')\n",
    "model_uri = f'runs:/{run_id}/model_name'\n",
    "\n",
    "with mlflow.start_run(run_id=run_id):\n",
    "    mlflow.register_model(model_uri=model_uri, name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb5b7c3-38ad-43a4-9ca7-b3fa207dec20",
   "metadata": {},
   "source": [
    "##### Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a9ae13-4c7e-43a2-9fbb-9f2bfdbdbd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version = 1\n",
    "model_uri = f\"models:/{model_name}/{model_version}\"\n",
    "\n",
    "loaded_model = mlflow.xgboost.load_model(model_uri)\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "y_pred[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d5e13d-2525-43b4-8f83-612adef85cc4",
   "metadata": {},
   "source": [
    "##### Transition the Model to Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0af85e-6bc8-464e-af5c-8fb1a0349318",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_model_uri = f\"models:/{model_name}@challenger\"\n",
    "production_model_name = \"anomaly-detection-prod\"\n",
    "\n",
    "client = mlflow.MlflowClient()\n",
    "client.copy_model_version(src_model_uri=current_model_uri, dst_name=production_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ca6715-509a-4f40-80fd-109c1ab8e9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version = 1\n",
    "prod_model_uri = f\"models:/{production_model_name}@champion\"\n",
    "\n",
    "loaded_model = mlflow.xgboost.load_model(prod_model_uri)\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "y_pred[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4ddbe1-af6c-4291-bddc-6e2744a7683b",
   "metadata": {},
   "source": [
    "Please refer to following to learn more about model registry\n",
    "\n",
    "https://mlflow.org/docs/latest/model-registry.html#model-registry-workflows to learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e021d356-60d4-4994-931a-fe70ed721606",
   "metadata": {},
   "source": [
    "#### 12.6: ML Flow Centralized Server Using Dagshub\n",
    "- Dagsub is similar to GitHub. It allows code version control and collaboration.\n",
    "- Dagshub has additional features such as:\n",
    "  - Data Version Control\n",
    "  - Experiment Tracking\n",
    "- Data scientists can use Dagshub to publish experiment metrics on a centralized server.\n",
    "- For more details about Dagshub implimentation please refer `ml_flow_dagshub` notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304e392b-7c53-4710-8d8f-0549ca22267c",
   "metadata": {},
   "source": [
    "#### 12.8: What is API ?\n",
    "- API stands for Application Programming Interface.\n",
    "- FastAPI, Flask, Node JS, etc. are web frameworks that allow you to build APIs.\n",
    "- FastAPI is a modern and better framework that many ML practitioners use to build servers for their models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2561d496-c0e0-45fa-8189-ec8eab06aa70",
   "metadata": {},
   "source": [
    "#### 12.9: FastAPI Basics\n",
    "- pip install fastapi[standard]\n",
    "- FastAPI is a web framework that lets you build servers that can serve inference requests.\n",
    "- FastAPI is a modern framework that offers several benefits over other options such as Flask.\n",
    "- The benefits are:\n",
    "  - Speed\n",
    "  - In-built data validation\n",
    "  - In-built documentation\n",
    "  - Faster code development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64c8185-daea-47cb-9525-f2afd2f7ee35",
   "metadata": {},
   "source": [
    "#### 12.10: Build Fast API Server For Credit Risk Project\n",
    "- Data scientists and AI engineers use Postman tool to test backend inference server.\n",
    "- Pydantic is a Python module used for data validation.\n",
    "- It can be used along with FastAPI to validate input and output to the server.\n",
    "- A smart AI engineer / Data Scientist uses AI tools such as ChatGPT, claude.ai, meta.ai to write code faster and boost productivity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6387f3e1-e51c-4772-9fe8-4945cd2a532b",
   "metadata": {},
   "source": [
    "#### 12.15: AWS Sagemaker: Sagemaker Studio\n",
    "- AWS Sagemaker is one of the popular cloud platforms that allows you to streamline your end-to-end ML project development workflow.\n",
    "- You can enroll to AWS free tier and you will get certain free benefits.\n",
    "- SageMaker Studio provides an integrated development environment for end-to-end machine learning workflows.\n",
    "- It offers seamless collaboration and version control for data scientists and developers.\n",
    "- The visual interface simplifies Data preparation, Model training, Tuning, Deployment.\n",
    "- It integrates with other AWS services, enabling a comprehensive and scalable machine learning ecosystem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105b57b6-d11b-41b0-8e28-1139423974fa",
   "metadata": {},
   "source": [
    "#### 12.16: AWS Sagemaker: 4 Ways to Train Model\n",
    "- SageMaker offers various ways to run model training.\n",
    "- 4 prominent ways are:\n",
    "  - Training inside notebook\n",
    "  - Built-in algorithms\n",
    "  - Script mode\n",
    "  - Custom containers\n",
    "    - Custom containers require you to build your own Docker container and deploy it along with all its dependencies.\n",
    "Using built-in algorithms or script mode will save all this effort for you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44b2067-6040-4727-a27c-1907aec68f9c",
   "metadata": {},
   "source": [
    "#### 12.17: AWS Sagemaker - Built In Algorithms\n",
    "- Built-in algorithms allow you to use inbuilt containers inside the SageMaker environment to run the model training.\n",
    "This speeds up model development.\n",
    "- Many times, people need high compute with GPUs just for training, while using lower-end computers for data processing and writing code in the notebook. Built-in algorithms allow you to run just the training on high compute while keeping the rest on a different cloud computer.\n",
    "- SageMaker’s built-in algorithms are optimized for performance and scalability, handling large datasets efficiently.\n",
    "- For BuiltIn model training example plese refer `builtin_algo_classification` notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788d550d-7513-45c2-932d-1d6d4c3a8924",
   "metadata": {},
   "source": [
    "#### 12.18: AWS Sagemaker - Script Mode\n",
    "- Script mode in SageMaker allows you to run model training using your own Python script. This method is more customizable compared to a Built-In Algorithm.\n",
    "- Just like Built-In Algorithms, it uses pre-built containers (or Docker images) to run the training. This saves time required for model training in the cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa06850e-e928-4273-a320-a23b1d847dbd",
   "metadata": {},
   "source": [
    "#### 12.20: Data Drift Detection Using PSI & CSI\n",
    "- PSI and CSI are the ways to measure data drift.\n",
    "- PSI is mainly used to measure overall drift in a population (mainly for target variable distribution changes).\n",
    "- PSI > 0.2 is considered a high level of data drift that warrants investigation.\n",
    "- Note: 0.2 is not a fixed threshold. Threshold can vary based on the situation.\n",
    "- CSI is a way to measure drift in a feature (or independent variable).\n",
    "- The formula is exactly the same.\n",
    "- For categorical variables, use categories to measure Expected % and Actual % for CSI.\n",
    "- For continuous variables, bin them to measure Expected % and Actual % for CSI."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
